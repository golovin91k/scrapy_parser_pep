Настоящий парсер написан с использованием  фреймворка Scrapy.

Парсер предназначен для получения списка PEP-документов с их номерами, названием и статусом, а также для подсчета количества PEP-документов, находящихся в соответствующем статусе.

Для работы парсеры необходимо выполнить следующие действия:
- загрузить репозиторой себе на диск;
- создать и активировать виртуальное окружение;
- установить зависимости из файла requirements.txt;
- из корневой папки парсеры выполнить команду: scrapy crawl pep

В результате работы парсера в папке results/ должны появиться два файла с расширением .csv, в которых будет содержаться информация о PEP-документах (файл с префиксом pep_) и подсчет количества PEP-документов, находящихся в соответствующем статусе (файл с префиксом status_summary_)

Над проектом работал Головин Кирилл golovin91k@gmail.com
При поддержке Яндекс Практикума.